{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "import time\n",
    "from math import log\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# kernel = 'kaggle'\n",
    "kernel = 'local'\n",
    "path = '../input/' if kernel == 'kaggle' else 'input\\\\'\n",
    "\n",
    "catalog = {'train': 'sales_train.csv',\n",
    "           'test': 'test.csv',\n",
    "           'items': 'items.csv',\n",
    "           'categories': 'item_categories.csv',\n",
    "           'shops': 'shops.csv',\n",
    "}\n",
    "catalog = {k: path+v for k, v in catalog.items()}\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "        self.last = self.start\n",
    "        \n",
    "    def lap(self, *sections):\n",
    "        end = time.time()\n",
    "        lap_time = timedelta(seconds=int(end-self.last)) \n",
    "        total_time = timedelta(seconds=int(end-self.start))\n",
    "        self.last = end\n",
    "        print('total: '+str(total_time)\n",
    "              +' | section: '+str(lap_time)\n",
    "              +' | '+ ' | '.join(sections))\n",
    "\n",
    "l = Logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test\n",
    "from datetime import datetime\n",
    "\n",
    "train = pd.read_csv(catalog['train'])\n",
    "train['date'] = pd.to_datetime(train['date'],  format='%d.%m.%Y')\n",
    "train['quarter'] = train['date'].dt.quarter\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "\n",
    "test = pd.read_csv(catalog['test'])\n",
    "test['date'] = datetime(day=1,month=11,year=2015)\n",
    "test['quarter'] = test['date'].dt.quarter\n",
    "test['month'] = test['date'].dt.month\n",
    "test['year'] = test['date'].dt.year\n",
    "\n",
    "\n",
    "def _compare(*cols):\n",
    "    cols, nm = list(cols), \",\".join(cols)\n",
    "    df1, df2 = train[cols].drop_duplicates(), test[cols].drop_duplicates()\n",
    "    df3 = df1.merge(df2, on=cols, how='outer', indicator=True)\n",
    "    v_count, v_count.name = df3['_merge'].value_counts(), nm\n",
    "    v_count.index = v_count.index.map({'both': 'both', \n",
    "                                       'left_only': 'train_only', \n",
    "                                       'right_only': 'test_only'})\n",
    "    print(v_count, '\\n')\n",
    "    del df1, df2, df3, v_count\n",
    "    gc.collect()\n",
    "    \n",
    "_compare('shop_id')\n",
    "_compare('item_id')\n",
    "_compare('item_id', 'shop_id')\n",
    "\n",
    "print('last block ', train['date_block_num'].max())\n",
    "print('last date  ', train['date'].max())\n",
    "\n",
    "l.lap('train & test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# boxplot to identify extreme values\n",
    "ax1 = plt.subplot(211)\n",
    "sns.boxplot(train.item_cnt_day, ax=ax1)\n",
    "plt.title('item_cnt_day')\n",
    "ax1 = plt.subplot(212)\n",
    "sns.boxplot(train.item_price, ax=ax1)\n",
    "\n",
    "# Clip prices and item_counts to more reasonable levels\n",
    "train['item_cnt_day'] = train['item_cnt_day'].clip(0, 1001)\n",
    "train['item_price'] = train['item_price'].clip(0, 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) combine train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train['ID'] = -1\n",
    "\n",
    "# Fix Test\n",
    "test['date_block_num'] = 34\n",
    "test['item_cnt_day'] = 0\n",
    "test['item_price'] = 0\n",
    "# Combine\n",
    "combo = pd.concat([train, test])\n",
    "\n",
    "del train, test\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) grid - shop_id x item_id for each date_block_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(df):\n",
    "    from itertools import product\n",
    "    cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "    grid = []\n",
    "    for block in df['date_block_num'].unique():\n",
    "        shops = df.loc[df['date_block_num']==block]['shop_id'].unique()\n",
    "        items = df.loc[df['date_block_num']==block]['item_id'].unique()\n",
    "        grid.append(np.array(list(product([block], shops, items))))\n",
    "    grid = pd.DataFrame(np.vstack(grid), columns=cols)\n",
    "    return grid\n",
    "\n",
    "grid = get_grid(combo)\n",
    "\n",
    "l.lap('preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) month features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekdays(month, year):\n",
    "    start = datetime(day=1, month=month, year=year)\n",
    "    \n",
    "    year = year if month != 12 else year + 1\n",
    "    month = month + 1 if month != 12 else 1\n",
    "    end = datetime(day=1, month=month, year=year)\n",
    "    return pd.date_range(start, end, closed='left' ).weekday.value_counts().sort_index().tolist()\n",
    "\n",
    "month_feat = combo[['date_block_num', 'month', 'year', 'quarter']].drop_duplicates()\n",
    "weekdays = month_feat.apply(lambda x: get_weekdays(x['month'], x['year']), axis=1)\n",
    "weekdays = pd.DataFrame.from_items(zip(weekdays.index, weekdays.values)).T\n",
    "weekdays.columns = ['wk_'+str(w) for w in weekdays if w != 'date_block_num']\n",
    "month_feat = pd.concat([month_feat, weekdays], axis=1)\n",
    "month_feat.drop('year', axis=1, inplace=True)\n",
    "\n",
    "grid = grid.merge(month_feat, how='left')\n",
    "\n",
    "month_feat = ['month', 'quarter']+['wk_'+str(i) for i in range(7)]\n",
    "\n",
    "l.lap('month features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) item_category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(catalog['items'])\n",
    "items.drop('item_name', axis=1, inplace=True)\n",
    "# Merge\n",
    "grid = grid.merge(items, on='item_id', how='left')\n",
    "combo = combo.merge(items, on='item_id', how='left')\n",
    "\n",
    "del items\n",
    "gc.collect()\n",
    "l.lap('item_category_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) item_category_group_1, item_category_group_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most category names are of the form 'group_1 - group_2'\n",
    "cats = pd.read_csv(catalog['categories'])\n",
    "foo = lambda x, idx: x.split(' - ')[idx] if len(x.split(' - ')) > idx else ''\n",
    "cats['item_category_group_1'] = cats['item_category_name'].map(lambda x: foo(x, 0))\n",
    "cats['item_category_group_2'] = cats['item_category_name'].map(lambda x: foo(x, 1))\n",
    "cats['item_category_group_1'] = pd.factorize(cats['item_category_group_1'])[0]\n",
    "cats['item_category_group_2'] = pd.factorize(cats['item_category_group_2'])[0]\n",
    "cats.drop('item_category_name', axis=1, inplace=True)\n",
    "# Merge\n",
    "grid = grid.merge(cats, on='item_category_id', how='left')\n",
    "combo = combo.merge(cats, on='item_category_id', how='left')\n",
    "\n",
    "del cats\n",
    "gc.collect()\n",
    "l.lap('item_category_groups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) shop_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First word of shop name is repeated\n",
    "shops = pd.read_csv(catalog['shops'])\n",
    "foo = lambda x, idx: x.split(' ')[idx] if len(x.split(' ')) > idx else ''\n",
    "shops['shop_group'] = shops['shop_name'].map(lambda x: foo(x, 0))\n",
    "shops['shop_group'] = pd.factorize(shops['shop_group'])[0]\n",
    "shops.drop('shop_name', axis=1, inplace=True)\n",
    "# Merge\n",
    "grid = grid.merge(shops, on='shop_id', how='left')\n",
    "combo = combo.merge(shops, on='shop_id', how='left')\n",
    "\n",
    "del shops\n",
    "gc.collect()\n",
    "l.lap('shop_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns\n",
    "cat_feat = ['item_id', 'shop_id', 'item_category_id',\n",
    "            'item_category_group_1', 'item_category_group_2', 'shop_group',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) monthly aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_month_cnt(df, *group_by):\n",
    "    nm = \"monthly_by_\"+\"_\".join(group_by)\n",
    "    cols = list(group_by) + ['date_block_num']\n",
    "    cnt = combo.groupby(cols, as_index=False)['item_cnt_day'].agg({nm: sum})\n",
    "    df = df.merge(cnt, how='left', on=cols+['date_block_num'])\n",
    "    df[nm] = df[nm].fillna(0)\n",
    "    del cnt\n",
    "    gc.collect()\n",
    "    l.lap('montly aggregates', \", \".join(group_by))\n",
    "    return df\n",
    "    \n",
    "# target\n",
    "grid = get_item_month_cnt(grid, 'shop_id', 'item_id')\n",
    "\n",
    "# target column\n",
    "target = 'monthly_by_shop_id_item_id'\n",
    "grid[target] = grid[target].clip(0, 20)\n",
    "\n",
    "# Monthly aggregate columns\n",
    "monthly_feat = [c for c in grid if 'monthly_by_' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) mean encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_encoding(df, *group_by):\n",
    "    nm = \"average_by_\"+\"_\".join(group_by)\n",
    "    cols = list(group_by) + ['date_block_num']\n",
    "    t_mean = df.groupby(cols, as_index=False)[target].agg({nm: 'mean'})\n",
    "    df = df.merge(t_mean, on=cols, how='left')\n",
    "    df[nm] = df[nm].fillna(0)\n",
    "    del t_mean\n",
    "    gc.collect()\n",
    "    l.lap('mean encoding', \", \".join(group_by))\n",
    "    return df\n",
    "\n",
    "# Level 1\n",
    "grid = get_mean_encoding(grid)\n",
    "grid = get_mean_encoding(grid, 'shop_id')  \n",
    "grid = get_mean_encoding(grid, 'item_id')  \n",
    "grid = get_mean_encoding(grid, 'item_category_id') \n",
    "grid = get_mean_encoding(grid, 'item_category_group_1') \n",
    "grid = get_mean_encoding(grid, 'item_category_group_2')\n",
    "grid = get_mean_encoding(grid, 'shop_group')\n",
    "grid = get_mean_encoding(grid, 'shop_id', 'item_category_group_1')\n",
    "grid = get_mean_encoding(grid, 'shop_id', 'item_category_group_2')\n",
    "grid = get_mean_encoding(grid, 'shop_group', 'item_id')\n",
    "\n",
    "# Monthly average columns\n",
    "mean_enc_cols = [c for c in grid if 'average_by_' in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) lag features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lagged_features(grid, \n",
    "                        shift_range, \n",
    "                        lag_cols, \n",
    "                        index_cols=['shop_id', 'item_id', 'date_block_num']):\n",
    "    for shift in shift_range:\n",
    "        grid_shift = grid[index_cols+lag_cols].copy()\n",
    "        grid_shift['date_block_num'] = grid_shift['date_block_num'] + shift\n",
    "        foo = lambda x: '{}_lag_{}'.format(x, shift) if x in lag_cols else x\n",
    "        grid_shift = grid_shift.rename(columns=foo)\n",
    "        grid = pd.merge(grid, grid_shift, on=index_cols, how='left').fillna(0)\n",
    "        l.lap('lagged features', str(shift))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) item_price_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn1 = combo.groupby('item_id', as_index=False)['item_price'].agg({'global': 'mean'})\n",
    "mn2 = combo.groupby(['date_block_num', 'item_id'], \n",
    "                    as_index=False)['item_price'].agg({'month': 'mean'})\n",
    "mn3 = mn2.merge(mn1, on='item_id', how='left')\n",
    "mn3 = get_lagged_features(mn3, range(1,7), ['month'], ['item_id', 'date_block_num'])\n",
    "\n",
    "lag_cols = [col for col in mn3.columns if '_lag_' in col]\n",
    "for col in lag_cols:\n",
    "    mn3[col] = (mn3[col]-mn3['month'])/mn3['global']\n",
    "    \n",
    "foo = lambda x: x[np.where(x!=0)[0][0]] if len(np.where(x!=0)[0]) != 0 else 0\n",
    "\n",
    "mn3['item_price_trend'] = mn3[lag_cols].apply(foo, axis=1)\n",
    "mn3['item_price_trend'] = mn3['item_price_trend'].fillna(0)\n",
    "mn3 = mn3[['date_block_num', 'item_id', 'item_price_trend']]\n",
    "\n",
    "grid = grid.merge(mn3, on=['date_block_num', 'item_id'], how='left')\n",
    "\n",
    "del mn1, mn2, mn3\n",
    "gc.collect()\n",
    "\n",
    "l.lap('item_price_trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) shop_revenue_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo['shop_revenue'] = combo['item_price'].astype('float64') * combo['item_cnt_day']\n",
    "mn2 = (combo\n",
    "       .loc[combo['date_block_num']<34]\n",
    "       .groupby(['shop_id', 'date_block_num'], as_index=False)\n",
    "       ['shop_revenue']\n",
    "       .agg({'month': 'sum'}))\n",
    "mn1 = mn2.groupby('shop_id', as_index=False)['month'].agg({'global': 'mean'})\n",
    "mn3 = mn2.merge(mn1, on='shop_id', how='left')\n",
    "mn3 = get_lagged_features(mn3, range(1,7), ['month'], ['shop_id', 'date_block_num'])\n",
    "\n",
    "lag_cols = [col for col in mn3.columns if '_lag_' in col]\n",
    "for col in lag_cols:\n",
    "    mn3[col] = (mn3[col]-mn3['month'])/mn3['global']\n",
    "    \n",
    "foo = lambda x: x[np.where(x!=0)[0][0]] if len(np.where(x!=0)[0]) != 0 else 0\n",
    "\n",
    "mn3['shop_revenue_trend'] = mn3[lag_cols].apply(foo, axis=1)\n",
    "mn3['shop_revenue_trend'] = mn3['shop_revenue_trend'].fillna(0)\n",
    "mn3 = mn3[['date_block_num', 'shop_id', 'shop_revenue_trend']]\n",
    "\n",
    "grid = grid.merge(mn3, on=['date_block_num', 'shop_id'], how='left')\n",
    "\n",
    "del mn1, mn2, mn3\n",
    "gc.collect()\n",
    "\n",
    "l.lap('shop_revenue_trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) downcasting dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid is 2gbs of memory, downcasting floats and ints to reduce to a quarter\n",
    "def downcast_dtypes(df, cols=None):\n",
    "    cols = cols if cols else df.columns.tolist()\n",
    "    int_cols = df.select_dtypes(include=['int'+str(b) for b in [8,16,32,64]]).columns\n",
    "    float_cols = df.select_dtypes(include=['float'+str(b) for b in [16,32,64]]).columns\n",
    "    int_cols = [c for c in int_cols if c in cols]\n",
    "    float_cols = [c for c in float_cols if c in cols]\n",
    "    for col in int_cols:\n",
    "        log_max = log(df[col].abs().max(), 2)\n",
    "        base = min([v for v in [8,16,32,64] if v > log_max])\n",
    "        dtype = 'int'+str(base)\n",
    "        if df[col].dtype.name != dtype:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "            \n",
    "    for col in float_cols:\n",
    "        log_max = log(df[col].abs().max(), 2)\n",
    "        base = min([v for v in [16,32,64] if v > log_max])\n",
    "        dtype = 'float'+str(base)\n",
    "        if df[col].dtype.name != dtype:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "    return df\n",
    "\n",
    "grid = downcast_dtypes(grid)\n",
    "l.lap('downcast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Zeros %')\n",
    "round((grid == 0).sum()/grid.shape[0]*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "grid = get_lagged_features(grid, [1,2,3,6,12], mean_enc_cols, idx)\n",
    "grid = get_lagged_features(grid, [1], ['item_price_trend', 'shop_revenue_trend'], idx)\n",
    "grid.drop(mean_enc_cols+['item_price_trend', 'shop_revenue_trend'], axis=1, inplace=True)\n",
    "grid = grid.loc[grid['date_block_num'] >= 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.info()\n",
    "\n",
    "del combo\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) save/load grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quarter', 'wk_0', 'wk_1', 'wk_2', 'wk_3', 'wk_4', 'wk_5', 'wk_6']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "grid = pd.read_hdf('intermediate//grid', 'grid')\n",
    "target = 'monthly_by_shop_id_item_id'\n",
    "exclude = [\n",
    "#     'month',\n",
    "    'quarter',\n",
    "    'wk_0', \n",
    "    'wk_1', \n",
    "    'wk_2', \n",
    "    'wk_3', \n",
    "    'wk_4', \n",
    "    'wk_5', \n",
    "    'wk_6'\n",
    "]\n",
    "features = grid.columns.difference([target, 'date_block_num']+exclude)\n",
    "dates = grid['date_block_num']\n",
    "X = grid[features]\n",
    "y = grid[target]\n",
    "\n",
    "del grid\n",
    "gc.collect()\n",
    "exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cross val functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "\n",
    "def get_score(y, prediction):\n",
    "    return np.sqrt(mean_squared_error(y, prediction.clip(0,20)))\n",
    "\n",
    "def train_test_split(X, y, block):\n",
    "    X_train = X.loc[dates < block]\n",
    "    y_train = y.loc[dates < block]\n",
    "    X_test = X.loc[dates == block]\n",
    "    y_test = y.loc[dates == block]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def cross_val(model, X, y, block_range):\n",
    "    scores = pd.DataFrame(columns=['train', 'test'], index=block_range)\n",
    "    predictions = pd.Series(index=dates[dates.isin(block_range)], name='prediction')\n",
    "\n",
    "    for block in block_range:\n",
    "        m = clone(model)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, block)\n",
    "        \n",
    "        m.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = m.predict(X_train)\n",
    "        score_train = get_score(y_train.values, pred_train)\n",
    "        scores.loc[block, 'train'] = score_train\n",
    "        \n",
    "        pred_test = m.predict(X_test)\n",
    "        score_test = get_score(y_test.values, pred_test)\n",
    "        scores.loc[block, 'test'] = score_test\n",
    "        predictions.loc[block] =  pred_test\n",
    "        \n",
    "        del m, X_train, y_train, X_test, y_test\n",
    "        gc.collect()\n",
    "        \n",
    "        l.lap(str(block), '{:.2f}'.format(score_train), '{:.2f}'.format(score_test))\n",
    "    return scores, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Features & target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 0:38:41 | section: 0:00:54 | 22 | 0.80 | 0.99\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb_params = {\n",
    "    'feature_fraction': 0.75, \n",
    "    'nthread': -1, \n",
    "    'min_data_in_leaf': 2**7,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'learning_rate': 0.03,\n",
    "    'objective': 'mse',\n",
    "    'num_leaves': 2**7,\n",
    "    'bagging_freq': 1,\n",
    "    'n_estimators': 100\n",
    "    }\n",
    "\n",
    "block_range = range(22,23)\n",
    "lgb_model = LGBMRegressor(**lgb_params)\n",
    "lgb_res, lgb_pred = cross_val(lgb_model, X, y, block_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge_score, ridge_pred = cross_val(ridge, X, y block_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "lasso_res, lasso_pred = cross_val(lasso, block_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PCA\n",
    "\n",
    "neigh = make_pipeline(PCA(n_components=32), KNeighborsRegressor(n_jobs=-1))\n",
    "neigh_res, neigh_pred = cross_val(neigh, block_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(prediction, save=False):\n",
    "    test = pd.read_csv(catalog['test'])\n",
    "    submission = pd.DataFrame(data={'ID': test.ID, \n",
    "                                    'item_cnt_month': prediction.clip(0,20)}\n",
    "                             )\n",
    "    if save:\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.75, bagging_freq=1, boosting_type='gbdt',\n",
       "       colsample_bytree=1, feature_fraction=0.75, learning_rate=0.03,\n",
       "       max_bin=255, max_depth=-1, min_child_samples=10, min_child_weight=5,\n",
       "       min_data_in_leaf=128, min_split_gain=0, n_estimators=100,\n",
       "       nthread=-1, num_leaves=128, objective='mse', reg_alpha=0,\n",
       "       reg_lambda=0, seed=0, silent=True, subsample=1,\n",
       "       subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 34)\n",
    "lgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.535855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.202071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.055191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.512488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.075977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.656605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.983450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.134337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.514052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.826054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2.600224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.275699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.130469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.413267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.429148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2.918875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.058424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.145526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.175607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.252197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.384402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.301632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2.095679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.427555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.251256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.693940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.316974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.564679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.055266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>4.604621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214170</th>\n",
       "      <td>214170</td>\n",
       "      <td>0.041988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214171</th>\n",
       "      <td>214171</td>\n",
       "      <td>0.026130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214172</th>\n",
       "      <td>214172</td>\n",
       "      <td>0.045331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214173</th>\n",
       "      <td>214173</td>\n",
       "      <td>0.149001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214174</th>\n",
       "      <td>214174</td>\n",
       "      <td>0.061878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214175</th>\n",
       "      <td>214175</td>\n",
       "      <td>0.068964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214176</th>\n",
       "      <td>214176</td>\n",
       "      <td>0.285327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214177</th>\n",
       "      <td>214177</td>\n",
       "      <td>0.043566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214178</th>\n",
       "      <td>214178</td>\n",
       "      <td>0.077634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214179</th>\n",
       "      <td>214179</td>\n",
       "      <td>1.311444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214180</th>\n",
       "      <td>214180</td>\n",
       "      <td>0.285327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214181</th>\n",
       "      <td>214181</td>\n",
       "      <td>0.066190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214182</th>\n",
       "      <td>214182</td>\n",
       "      <td>0.074294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214183</th>\n",
       "      <td>214183</td>\n",
       "      <td>0.284786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214184</th>\n",
       "      <td>214184</td>\n",
       "      <td>0.074058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214185</th>\n",
       "      <td>214185</td>\n",
       "      <td>0.071236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214186</th>\n",
       "      <td>214186</td>\n",
       "      <td>0.046636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214187</th>\n",
       "      <td>214187</td>\n",
       "      <td>0.106019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214188</th>\n",
       "      <td>214188</td>\n",
       "      <td>0.062157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214189</th>\n",
       "      <td>214189</td>\n",
       "      <td>0.104967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214190</th>\n",
       "      <td>214190</td>\n",
       "      <td>0.045211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214191</th>\n",
       "      <td>214191</td>\n",
       "      <td>0.072189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214192</th>\n",
       "      <td>214192</td>\n",
       "      <td>0.072189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214193</th>\n",
       "      <td>214193</td>\n",
       "      <td>0.076660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214194</th>\n",
       "      <td>214194</td>\n",
       "      <td>0.048345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214195</th>\n",
       "      <td>214195</td>\n",
       "      <td>0.082157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214196</th>\n",
       "      <td>214196</td>\n",
       "      <td>0.046936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214197</th>\n",
       "      <td>214197</td>\n",
       "      <td>0.072434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214198</th>\n",
       "      <td>214198</td>\n",
       "      <td>0.042711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214199</th>\n",
       "      <td>214199</td>\n",
       "      <td>0.082555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  item_cnt_month\n",
       "0            0        0.535855\n",
       "1            1        0.202071\n",
       "2            2        1.055191\n",
       "3            3        0.512488\n",
       "4            4        3.075977\n",
       "5            5        0.656605\n",
       "6            6        0.983450\n",
       "7            7        0.134337\n",
       "8            8        0.514052\n",
       "9            9        0.826054\n",
       "10          10        2.600224\n",
       "11          11        0.275699\n",
       "12          12        0.130469\n",
       "13          13        0.413267\n",
       "14          14        1.429148\n",
       "15          15        2.918875\n",
       "16          16        0.058424\n",
       "17          17        0.145526\n",
       "18          18        1.175607\n",
       "19          19        0.252197\n",
       "20          20        0.384402\n",
       "21          21        0.301632\n",
       "22          22        2.095679\n",
       "23          23        0.427555\n",
       "24          24        1.251256\n",
       "25          25        0.693940\n",
       "26          26        0.316974\n",
       "27          27        0.564679\n",
       "28          28        1.055266\n",
       "29          29        4.604621\n",
       "...        ...             ...\n",
       "214170  214170        0.041988\n",
       "214171  214171        0.026130\n",
       "214172  214172        0.045331\n",
       "214173  214173        0.149001\n",
       "214174  214174        0.061878\n",
       "214175  214175        0.068964\n",
       "214176  214176        0.285327\n",
       "214177  214177        0.043566\n",
       "214178  214178        0.077634\n",
       "214179  214179        1.311444\n",
       "214180  214180        0.285327\n",
       "214181  214181        0.066190\n",
       "214182  214182        0.074294\n",
       "214183  214183        0.284786\n",
       "214184  214184        0.074058\n",
       "214185  214185        0.071236\n",
       "214186  214186        0.046636\n",
       "214187  214187        0.106019\n",
       "214188  214188        0.062157\n",
       "214189  214189        0.104967\n",
       "214190  214190        0.045211\n",
       "214191  214191        0.072189\n",
       "214192  214192        0.072189\n",
       "214193  214193        0.076660\n",
       "214194  214194        0.048345\n",
       "214195  214195        0.082157\n",
       "214196  214196        0.046936\n",
       "214197  214197        0.072434\n",
       "214198  214198        0.042711\n",
       "214199  214199        0.082555\n",
       "\n",
       "[214200 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_submission(pred, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
